{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score,ConfusionMatrixDisplay,hamming_loss,classification_report\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import utils, callbacks\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras import layers, models\nfrom keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.losses import CategoricalCrossentropy\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn import metrics\n#hello","metadata":{"execution":{"iopub.status.busy":"2023-09-13T20:11:40.273769Z","iopub.execute_input":"2023-09-13T20:11:40.274924Z","iopub.status.idle":"2023-09-13T20:11:40.285551Z","shell.execute_reply.started":"2023-09-13T20:11:40.274880Z","shell.execute_reply":"2023-09-13T20:11:40.284523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_folder = '/kaggle/input/indian-sign-language/Train'\nall_data = []\nfor folder in os.listdir(train_folder):\n    \n    label_folder = os.path.join(train_folder, folder)    \n    onlyfiles = [{'label':folder,'path':os.path.join(label_folder, f)} for f in os.listdir(label_folder) if os.path.isfile(os.path.join(label_folder, f))]\n    #print(onlyfiles)\n    all_data += onlyfiles\n    #print(all_data)\ndata_df = pd.DataFrame(all_data)\ndata_df","metadata":{"execution":{"iopub.status.busy":"2023-07-29T04:49:41.760771Z","iopub.execute_input":"2023-07-29T04:49:41.761558Z","iopub.status.idle":"2023-07-29T04:52:15.783821Z","shell.execute_reply.started":"2023-07-29T04:49:41.761520Z","shell.execute_reply":"2023-07-29T04:52:15.782769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_folder = '/kaggle/input/indian-sign-language/Test'\nall_data = []\nfor folder in os.listdir(test_folder):\n    \n    label_folder = os.path.join(test_folder, folder)    \n    onlyfiles = [{'label':folder,'path':os.path.join(label_folder, f)} for f in os.listdir(label_folder) if os.path.isfile(os.path.join(label_folder, f))]\n    #print(onlyfiles)\n    all_data += onlyfiles\n    #print(all_data)\ntest_df = pd.DataFrame(all_data)\ntest_df","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:48:38.169554Z","iopub.execute_input":"2023-09-13T18:48:38.169953Z","iopub.status.idle":"2023-09-13T18:48:41.248910Z","shell.execute_reply.started":"2023-09-13T18:48:38.169921Z","shell.execute_reply":"2023-09-13T18:48:41.247848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom scipy.ndimage import gaussian_filter\nimport numpy as np\n#import skimage.util\nfrom PIL import Image, ImageFilter \nfrom PIL import ImageEnhance\nfrom scipy.ndimage.interpolation import map_coordinates\nfrom scipy.ndimage.filters import gaussian_filter\nimport random\nimport cv2\n\nimg_width, img_height = 128, 128\nbatch_size = 128\ny_col = 'label'\nx_col = 'path'\nno_of_classes = len(data_df[y_col].unique())\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1/255.0,\n    rotation_range=20,\n    brightness_range=[0.8, 1.2],\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,    \n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=data_df, x_col=x_col, y_col=y_col,\n    target_size=(img_width, img_height),\n    class_mode='categorical',\n    batch_size=batch_size,\n    shuffle=True\n)\n\n# def elastic_transform(image, alpha=2, sigma=0.05, random_state=None):\n#     if random_state is None:\n#         random_state = np.random.RandomState(None)\n\n#     shape = image.shape\n#     dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n#     dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n#     dz = np.zeros_like(dx)\n\n#     x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]))\n#     indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n\n#     distored_image = map_coordinates(image, indices, order=1, mode='reflect')\n#     return distored_image.reshape(image.shape)\n\n# def color_jittering(image, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1):\n#     jittered_image = Image.fromarray(np.array(image).astype(np.uint8))\n\n#     enhancer = ImageEnhance.Brightness(jittered_image)\n#     jittered_image = enhancer.enhance(1 + random.uniform(-brightness, brightness))\n\n#     enhancer = ImageEnhance.Contrast(jittered_image)\n#     jittered_image = enhancer.enhance(1 + random.uniform(-contrast, contrast))\n\n#     enhancer = ImageEnhance.Color(jittered_image)\n#     jittered_image = enhancer.enhance(1 + random.uniform(-saturation, saturation))\n\n#     hsv_image = jittered_image.convert(\"HSV\")\n#     hue_shift = random.uniform(-hue, hue) * 255\n#     hsv_image = hsv_image.point(lambda x: (x + hue_shift) % 256)\n#     jittered_image = hsv_image.convert(\"RGB\")\n#     jittered_image = cv2.cvtColor(np.array(jittered_image), cv2.COLOR_RGB2BGR)\n\n#     return jittered_image\n\n\n# def gaussian_blur(image, sigma=1):\n    \n#     return cv2.GaussianBlur(image, (3, 3), 0)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T04:53:06.884132Z","iopub.execute_input":"2023-07-29T04:53:06.884719Z","iopub.status.idle":"2023-07-29T04:54:01.444303Z","shell.execute_reply.started":"2023-07-29T04:53:06.884686Z","shell.execute_reply":"2023-07-29T04:54:01.443152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom scipy.ndimage import gaussian_filter\nimport numpy as np\n#import skimage.util\nfrom PIL import Image, ImageFilter \nfrom PIL import ImageEnhance\nfrom scipy.ndimage.interpolation import map_coordinates\nfrom scipy.ndimage.filters import gaussian_filter\nimport random\nimport cv2\n\nimg_width, img_height = 128, 128\nbatch_size = 128\ny_col = 'label'\nx_col = 'path'\nno_of_classes = len(test_df[y_col].unique())\n\ntest_datagen = ImageDataGenerator(\n    rescale=1/255.0,\n        \n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df, x_col=x_col, y_col=y_col,\n    target_size=(img_width, img_height),\n    class_mode='categorical',\n    batch_size=batch_size,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:09:43.518954Z","iopub.execute_input":"2023-09-13T19:09:43.519655Z","iopub.status.idle":"2023-09-13T19:09:54.811227Z","shell.execute_reply.started":"2023-09-13T19:09:43.519621Z","shell.execute_reply":"2023-09-13T19:09:54.810212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import Callback\ncomp_recorded_times=[]\ncomp_recorded_accuracy=[]\ncomp_recorded_loss=[]\n\n\nclasses = 36\nepochs = 10\nlearning_rate = 0.0001\nsteps_per_epoch=np.ceil(103282/128) \nadam = Adam(learning_rate=learning_rate)\n\nclass TimePerEpochCallback(Callback):\n    def on_train_begin(self, logs=None):\n        self.times = []\n\n    def on_epoch_begin(self, epoch, logs=None):\n        self.epoch_start_time = time.time()\n\n    def on_epoch_end(self, epoch, logs=None):\n        epoch_time = time.time() - self.epoch_start_time\n        self.times.append(epoch_time)\n        print(f\"Time taken for epoch {epoch + 1}: {epoch_time:.2f} seconds\")\n","metadata":{"execution":{"iopub.status.busy":"2023-07-29T04:54:01.445890Z","iopub.execute_input":"2023-07-29T04:54:01.446320Z","iopub.status.idle":"2023-07-29T04:54:04.906175Z","shell.execute_reply.started":"2023-07-29T04:54:01.446286Z","shell.execute_reply":"2023-07-29T04:54:04.905155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_to_compare=[]\nxception_base = Xception(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")\nfor layer in xception_base.layers:\n    layer.trainable = False\nflatten_layer = layers.Flatten()\ndense_layer_1 = layers.Dense(512, activation='relu')\ndropout_layer_1 = layers.Dropout(0.5)\nprediction_layer = layers.Dense(36, activation='softmax')\nmodel = models.Sequential([\n    xception_base,\n    flatten_layer,\n    dense_layer_1,\n    dropout_layer_1,\n    prediction_layer\n])\nmodel.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\nmodels_to_compare.append((\"Xception\", model))\n\n\nfrom tensorflow.keras.applications import VGG19\nvgg19_base = VGG19(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")\nfor layer in vgg19_base.layers:\n    layer.trainable = False\nflatten_layer = layers.Flatten()\ndense_layer_1 = layers.Dense(512, activation='relu')\ndropout_layer_1 = layers.Dropout(0.5)\nprediction_layer = layers.Dense(36, activation='softmax')\nmodel = models.Sequential([\n    vgg19_base,\n    flatten_layer,\n    dense_layer_1,\n    dropout_layer_1,\n    prediction_layer\n])\nmodel.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\nmodels_to_compare.append((\"VGG19\", model))\n\n\nfrom tensorflow.keras.applications import ResNet50\nResnet50V1_base = ResNet50(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")\nfor layer in Resnet50V1_base.layers:\n    layer.trainable = False\nflatten_layer = layers.Flatten()\ndense_layer_1 = layers.Dense(512, activation='relu')\ndropout_layer_1 = layers.Dropout(0.5)\nprediction_layer = layers.Dense(36, activation='softmax')\nmodel = models.Sequential([\n    Resnet50V1_base,\n    flatten_layer,\n    dense_layer_1,\n    dropout_layer_1,\n    prediction_layer\n])\nmodel.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\nmodels_to_compare.append((\"ResNet50\", model))\n\n\nfrom tensorflow.keras.applications import EfficientNetB7\nEfficientNetB7_base = EfficientNetB7(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")\nfor layer in EfficientNetB7_base.layers:\n    layer.trainable = False\nflatten_layer = layers.Flatten()\ndense_layer_1 = layers.Dense(512, activation='relu')\ndropout_layer_1 = layers.Dropout(0.5)\nprediction_layer = layers.Dense(36, activation='softmax')\nmodel = models.Sequential([\n    EfficientNetB7_base,\n    flatten_layer,\n    dense_layer_1,\n    dropout_layer_1,\n    prediction_layer\n])\nmodel.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\nmodels_to_compare.append((\"EfficientNet\", model))","metadata":{"execution":{"iopub.status.busy":"2023-07-29T04:54:04.910922Z","iopub.execute_input":"2023-07-29T04:54:04.913216Z","iopub.status.idle":"2023-07-29T04:54:25.025142Z","shell.execute_reply.started":"2023-07-29T04:54:04.913180Z","shell.execute_reply":"2023-07-29T04:54:25.024165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model_with_time(model, data_generator, num_epochs):\n    epochs = 10\n    recorded_times = []\n    recorded_accuracy = []\n    recorded_loss = []\n    for epoch in range(epochs):\n        start_time = time.time()\n        print(\"epoch: \",epoch)\n        history = model.fit(data_generator, epochs=1, verbose=0)\n        end_time = time.time()\n\n        # Record metrics\n        epoch_time = end_time - start_time\n        epoch_accuracy = history.history['accuracy'][0]\n        epoch_loss = history.history['loss'][0]\n\n        recorded_times.append(epoch_time)\n        recorded_accuracy.append(epoch_accuracy)\n        recorded_loss.append(epoch_loss)\n\n        print(f\"Epoch {epoch + 1}/{epochs} - Time: {epoch_time:.2f}s - Accuracy: {epoch_accuracy:.4f} - Loss: {epoch_loss:.4f}\")\n\n    return recorded_loss, recorded_accuracy, recorded_times","metadata":{"execution":{"iopub.status.busy":"2023-07-29T04:54:25.026735Z","iopub.execute_input":"2023-07-29T04:54:25.027088Z","iopub.status.idle":"2023-07-29T04:54:25.039064Z","shell.execute_reply.started":"2023-07-29T04:54:25.027055Z","shell.execute_reply":"2023-07-29T04:54:25.037662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results=[]\nfor model_name, model in models_to_compare:\n    print(f\"Training {model_name}...\")\n    loss, accuracy, epoch_times = train_model_with_time(model, train_generator, epochs)\n    results.append((model_name, loss, accuracy, epoch_times))","metadata":{"execution":{"iopub.status.busy":"2023-07-29T04:54:25.040283Z","iopub.execute_input":"2023-07-29T04:54:25.041165Z","iopub.status.idle":"2023-07-29T11:45:41.349460Z","shell.execute_reply.started":"2023-07-29T04:54:25.041130Z","shell.execute_reply":"2023-07-29T11:45:41.348361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Compare the loss of each epoch for each model\nfor model_name, loss, _, _ in results:\n    plt.plot(range(1, epochs + 1), loss, label=model_name)\n\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss Comparison for Different Models')\nplt.legend()\nplt.show()\n\n# Compare the accuracy of each epoch for each model\nfor model_name, _, accuracy, _ in results:\n    plt.plot(range(1, epochs + 1), accuracy, label=model_name)\n\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Accuracy Comparison for Different Models')\nplt.legend()\nplt.show()\n\n# Compare the epoch times for each model\nfor model_name, _, _, epoch_times in results:\n    plt.plot(range(1, epochs + 1), epoch_times, label=model_name)\n\nplt.xlabel('Epochs')\nplt.ylabel('Time per Epoch (seconds)')\nplt.title('Epoch Times Comparison for Different Models')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:00:28.298640Z","iopub.execute_input":"2023-07-29T12:00:28.299030Z","iopub.status.idle":"2023-07-29T12:00:29.220279Z","shell.execute_reply.started":"2023-07-29T12:00:28.299000Z","shell.execute_reply":"2023-07-29T12:00:29.219346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_filename=\"results.pkl\"\nwith open(\"results.pkl\",\"wb\") as file:\n    pickle.dump(results, file)\nos.rename(history_filename, '/kaggle/working/' + history_filename)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:01:02.378188Z","iopub.execute_input":"2023-07-29T12:01:02.378557Z","iopub.status.idle":"2023-07-29T12:01:02.384286Z","shell.execute_reply.started":"2023-07-29T12:01:02.378527Z","shell.execute_reply":"2023-07-29T12:01:02.383344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xception = tf.keras.models.load_model('/kaggle/working/Xception.h5')\nVGG19 = tf.keras.models.load_model('/kaggle/working/VGG19.h5')\nResNet50 = tf.keras.models.load_model('/kaggle/working/ResNet50.h5')\n#EfficientNet = tf.keras.models.load_model('/kaggle/working/EfficientNet.h5')","metadata":{"execution":{"iopub.status.busy":"2023-09-13T20:19:02.382756Z","iopub.execute_input":"2023-09-13T20:19:02.383161Z","iopub.status.idle":"2023-09-13T20:19:09.283167Z","shell.execute_reply.started":"2023-09-13T20:19:02.383130Z","shell.execute_reply":"2023-09-13T20:19:09.282118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions using the models\ny_pred1 = Xception.predict(test_generator)\ny_pred2 = VGG19.predict(test_generator)\ny_pred3 = ResNet50.predict(test_generator)\n\n# Get predicted classes\ny_pred_classes1 = np.argmax(y_pred1, axis=1)\ny_pred_classes2 = np.argmax(y_pred2, axis=1)\ny_pred_classes3 = np.argmax(y_pred3, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T20:19:13.947783Z","iopub.execute_input":"2023-09-13T20:19:13.948626Z","iopub.status.idle":"2023-09-13T20:21:13.239642Z","shell.execute_reply.started":"2023-09-13T20:19:13.948594Z","shell.execute_reply":"2023-09-13T20:21:13.238623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc_test={}\nacc_test[\"Xception\"]=accuracy_score(true_labels,y_pred_classes1)\nacc_test[\"VGG19\"]=accuracy_score(true_labels,y_pred_classes2)\nacc_test[\"ResNet50\"]=accuracy_score(true_labels,y_pred_classes3)\nfor x in acc_test:\n    acc_test[x]*=100\n    print(x,\" : \",acc_test[x])\ncategories=acc_test.keys()\nvalues=acc_test.values()\nplt.bar(categories, values)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T20:17:24.380450Z","iopub.execute_input":"2023-09-13T20:17:24.381165Z","iopub.status.idle":"2023-09-13T20:17:24.633269Z","shell.execute_reply.started":"2023-09-13T20:17:24.381130Z","shell.execute_reply":"2023-09-13T20:17:24.628901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_labels= test_generator.classes\nprint(np.unique(true_labels))","metadata":{"execution":{"iopub.status.busy":"2023-09-13T20:16:48.390130Z","iopub.execute_input":"2023-09-13T20:16:48.391080Z","iopub.status.idle":"2023-09-13T20:16:48.401918Z","shell.execute_reply.started":"2023-09-13T20:16:48.391035Z","shell.execute_reply":"2023-09-13T20:16:48.400348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hamming_loss_dict={}\nhamming_loss_dict[\"Xception\"]=hamming_loss(true_labels,y_pred_classes1)\nhamming_loss_dict[\"VGG19\"]=hamming_loss(true_labels,y_pred_classes2)\nhamming_loss_dict[\"ResNet50\"]=hamming_loss(true_labels,y_pred_classes3)\nfor  x in hamming_loss_dict:\n    print(x,\" : \", hamming_loss_dict[x]*)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T20:12:31.499039Z","iopub.execute_input":"2023-09-13T20:12:31.499668Z","iopub.status.idle":"2023-09-13T20:12:31.546643Z","shell.execute_reply.started":"2023-09-13T20:12:31.499632Z","shell.execute_reply":"2023-09-13T20:12:31.545556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mat = {}\nconfusion_mat[\"Xception\"]=confusion_matrix(true_labels, y_pred_classes1)\nconfusion_mat[\"VGG19\"]=confusion_matrix(true_labels, y_pred_classes2)\nconfusion_mat[\"ResNet50\"]=confusion_matrix(true_labels, y_pred_classes3)\nfor x in confusion_mat:\n    print(x)\n    cmd=(ConfusionMatrixDisplay(confusion_mat[x]))\n    fig, ax = plt.subplots(figsize=(15, 15))\n    cmd.plot(ax=ax)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T20:17:42.448361Z","iopub.execute_input":"2023-09-13T20:17:42.449083Z","iopub.status.idle":"2023-09-13T20:17:52.842741Z","shell.execute_reply.started":"2023-09-13T20:17:42.449048Z","shell.execute_reply":"2023-09-13T20:17:52.841794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_report = {}\nclass_report[\"Xception\"]=classification_report(true_labels, y_pred_classes1)\nclass_report[\"VGG19\"]=classification_report(true_labels, y_pred_classes2)\nclass_report[\"ResNet50\"]=classification_report(true_labels, y_pred_classes3)\nfor x in class_report:\n    print(x)\n    print(class_report[x])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T19:49:01.941130Z","iopub.execute_input":"2023-09-13T19:49:01.941508Z","iopub.status.idle":"2023-09-13T19:49:02.088887Z","shell.execute_reply.started":"2023-09-13T19:49:01.941478Z","shell.execute_reply":"2023-09-13T19:49:02.087785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef custom_generator(train_generator):\n    for batch_images, batch_labels in train_generator:\n        batch_size = len(batch_images)\n        augmented_images = []\n        augmented_labels = []\n\n        for i in range(batch_size):\n            image = batch_images[i]\n            label = batch_labels[i]\n            image1=np.expand_dims(image, axis=0)\n            yield image1,np.tile(label, (image1.shape[0], 1))\n            \n#             # Apply elastic transformations\n#             transformed_image = elastic_transform(image)\n#             transformed_image = np.expand_dims(transformed_image, axis=0)\n#             yield transformed_image, np.tile(label, (transformed_image.shape[0], 1))\n            \n#             # Apply Gaussian noise\n#             noisy_image = skimage.util.random_noise(image)\n#             noisy_image = np.expand_dims(noisy_image, axis=0)            \n#             yield noisy_image, np.tile(label, (noisy_image.shape[0], 1))\n\n#             # Apply color jittering\n#             jittered_image = color_jittering(image)\n#             jittered_image = np.expand_dims(jittered_image, axis=0)                        \n#             yield jittered_image, np.tile(label, (jittered_image.shape[0], 1))            \n\n#             # Apply Gaussian blur\n#             blurred_image = gaussian_blur(image)\n#             blurred_image = np.expand_dims(blurred_image, axis=0)                                    \n#             yield blurred_image, np.tile(label, (blurred_image.shape[0], 1))\n\ncustom_train_generator = custom_generator(train_generator)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-15T07:25:13.428638Z","iopub.execute_input":"2023-07-15T07:25:13.433055Z","iopub.status.idle":"2023-07-15T07:25:13.442695Z","shell.execute_reply.started":"2023-07-15T07:25:13.433013Z","shell.execute_reply":"2023-07-15T07:25:13.441456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xception_base = Xception(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")\nfor layer in xception_base.layers:\n    layer.trainable = False\nflatten_layer = layers.Flatten()\ndense_layer_1 = layers.Dense(512, activation='relu')\ndropout_layer_1 = layers.Dropout(0.5)\nprediction_layer = layers.Dense(36, activation='softmax')\n\n\nmodel = models.Sequential([\n    xception_base,\n    flatten_layer,\n    dense_layer_1,\n    dropout_layer_1,\n    prediction_layer\n])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-15T07:25:13.444365Z","iopub.execute_input":"2023-07-15T07:25:13.445107Z","iopub.status.idle":"2023-07-15T07:25:20.155517Z","shell.execute_reply.started":"2023-07-15T07:25:13.445069Z","shell.execute_reply":"2023-07-15T07:25:20.154390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2023-07-15T07:25:20.157405Z","iopub.execute_input":"2023-07-15T07:25:20.158272Z","iopub.status.idle":"2023-07-15T07:25:20.184631Z","shell.execute_reply.started":"2023-07-15T07:25:20.158230Z","shell.execute_reply":"2023-07-15T07:25:20.183557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(\n    train_generator,\n    epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T07:25:20.186364Z","iopub.execute_input":"2023-07-15T07:25:20.186739Z","iopub.status.idle":"2023-07-15T09:33:22.672255Z","shell.execute_reply.started":"2023-07-15T07:25:20.186703Z","shell.execute_reply":"2023-07-15T09:33:22.671096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nimport os\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:58:40.940293Z","iopub.execute_input":"2023-07-16T08:58:40.940874Z","iopub.status.idle":"2023-07-16T08:58:40.945378Z","shell.execute_reply.started":"2023-07-16T08:58:40.940840Z","shell.execute_reply":"2023-07-16T08:58:40.944441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_filename = 'model_Xception_vanilla.h5'\nmodel.save(model_filename)\nos.rename(model_filename, '/kaggle/working/' + model_filename)\nhistory_filename=\"historyXception_vanilla.pkl\"\nwith open('historyXception_vanilla.pkl', 'wb') as file:\n    pickle.dump(history.history, file)\nos.rename(history_filename, '/kaggle/working/' + history_filename)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-15T09:38:09.395167Z","iopub.execute_input":"2023-07-15T09:38:09.395581Z","iopub.status.idle":"2023-07-15T09:38:10.536519Z","shell.execute_reply.started":"2023-07-15T09:38:09.395546Z","shell.execute_reply":"2023-07-15T09:38:10.535323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:59:01.172376Z","iopub.execute_input":"2023-07-16T08:59:01.173079Z","iopub.status.idle":"2023-07-16T08:59:02.351754Z","shell.execute_reply.started":"2023-07-16T08:59:01.173042Z","shell.execute_reply":"2023-07-16T08:59:02.351060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = 36\nepochs = 10\nlearning_rate = 0.0001\nsteps_per_epoch=np.ceil(103282/128) \nadam = Adam(lr=learning_rate)\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nhistory=model.fit(\n    train_generator,\n    epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:59:03.809657Z","iopub.execute_input":"2023-07-16T08:59:03.810015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_filename = 'model_vgg19_vanilla.h5'\nmodel.save(model_filename)\nos.rename(model_filename, '/kaggle/working/' + model_filename)\nhistory_filename=\"history_vgg19_vanilla.pkl\"\nwith open('history_vgg19_vanilla.pkl', 'wb') as file:\n    pickle.dump(history.history, file)\nos.rename(history_filename, '/kaggle/working/' + history_filename)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-15T11:47:08.110331Z","iopub.execute_input":"2023-07-15T11:47:08.110738Z","iopub.status.idle":"2023-07-15T11:47:08.387918Z","shell.execute_reply.started":"2023-07-15T11:47:08.110707Z","shell.execute_reply":"2023-07-15T11:47:08.386806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nResnet50V1_base = ResNet50(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")\nfor layer in Resnet50V1_base.layers:\n    layer.trainable = False\nflatten_layer = layers.Flatten()\ndense_layer_1 = layers.Dense(512, activation='relu')\ndropout_layer_1 = layers.Dropout(0.5)\nprediction_layer = layers.Dense(36, activation='softmax')\n\n\nmodel = models.Sequential([\n    Resnet50V1_base,\n    flatten_layer,\n    dense_layer_1,\n    dropout_layer_1,\n    prediction_layer\n])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-16T07:14:13.113738Z","iopub.execute_input":"2023-07-16T07:14:13.114092Z","iopub.status.idle":"2023-07-16T07:14:15.287396Z","shell.execute_reply.started":"2023-07-16T07:14:13.114063Z","shell.execute_reply":"2023-07-16T07:14:15.286455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = 36\nepochs = 10\nlearning_rate = 0.0001\nsteps_per_epoch=np.ceil(103282/128) \nadam = Adam(lr=learning_rate)\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nhistory=model.fit(\n    train_generator,\n    epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T07:14:34.883873Z","iopub.execute_input":"2023-07-16T07:14:34.884256Z","iopub.status.idle":"2023-07-16T08:55:45.101321Z","shell.execute_reply.started":"2023-07-16T07:14:34.884224Z","shell.execute_reply":"2023-07-16T08:55:45.100417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_filename = 'model_resnet_vanilla.h5'\nmodel.save(model_filename)\nos.rename(model_filename, '/kaggle/working/' + model_filename)\nhistory_filename=\"history_resnet_vanilla.pkl\"\nwith open('history_resnet_vanilla.pkl', 'wb') as file:\n    pickle.dump(history.history, file)\nos.rename(history_filename, '/kaggle/working/' + history_filename)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T08:58:46.890960Z","iopub.execute_input":"2023-07-16T08:58:46.891305Z","iopub.status.idle":"2023-07-16T08:58:47.925823Z","shell.execute_reply.started":"2023-07-16T08:58:46.891275Z","shell.execute_reply":"2023-07-16T08:58:47.924458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB7\nEfficientNetB7_base = EfficientNetB7(input_shape=(128, 128, 3), include_top=False, weights=\"imagenet\")\nfor layer in EfficientNetB7_base.layers:\n    layer.trainable = False\nflatten_layer = layers.Flatten()\ndense_layer_1 = layers.Dense(512, activation='relu')\ndropout_layer_1 = layers.Dropout(0.5)\nprediction_layer = layers.Dense(36, activation='softmax')\n\n\nmodel = models.Sequential([\n    EfficientNetB7_base,\n    flatten_layer,\n    dense_layer_1,\n    dropout_layer_1,\n    prediction_layer\n])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-15T11:51:20.547960Z","iopub.execute_input":"2023-07-15T11:51:20.548406Z","iopub.status.idle":"2023-07-15T11:51:34.901350Z","shell.execute_reply.started":"2023-07-15T11:51:20.548374Z","shell.execute_reply":"2023-07-15T11:51:34.900141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = 36\nepochs = 10\nlearning_rate = 0.0001\nsteps_per_epoch=np.ceil(103282/128) \nadam = Adam(lr=learning_rate)\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\nhistory=model.fit(\n    train_generator,\n    epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-15T11:52:03.361989Z","iopub.execute_input":"2023-07-15T11:52:03.363235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def elastic_transform(image, alpha=2, sigma=0.05, random_state=None):\n#     \"\"\"Elastic deformation of images as described in [Simard2003]_.\n#     .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n#        Convolutional Neural Networks applied to Visual Document Analysis\", in\n#        Proc. of the International Conference on Document Analysis and\n#        Recognition, 2003.\n#     \"\"\"\n#     if random_state is None:\n#         random_state = np.random.RandomState(None)\n\n#     shape = image.shape\n#     dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n#     dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n#     dz = np.zeros_like(dx)\n\n#     x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]))\n#     print(x.shape)\n#     indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n\n#     distored_image = map_coordinates(image, indices, order=1, mode='reflect')\n#     return distored_image.reshape(image.shape)\n\n# def add_gaussian_noise(image, mean=0, std=1):\n#     noisy_image = np.array(image)\n#     noise = np.random.normal(mean, std, size=noisy_image.shape).astype(np.uint8)\n#     noisy_image = cv2.add(image, noise)\n#     return Image.fromarray(noisy_image)\n\n# def color_jittering(image, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1):\n#     jittered_image = Image.fromarray(np.array(image).astype(np.uint8))\n\n#     enhancer = ImageEnhance.Brightness(jittered_image)\n#     jittered_image = enhancer.enhance(1 + random.uniform(-brightness, brightness))\n\n#     enhancer = ImageEnhance.Contrast(jittered_image)\n#     jittered_image = enhancer.enhance(1 + random.uniform(-contrast, contrast))\n\n#     enhancer = ImageEnhance.Color(jittered_image)\n#     jittered_image = enhancer.enhance(1 + random.uniform(-saturation, saturation))\n\n#     hsv_image = jittered_image.convert(\"HSV\")\n#     hue_shift = random.uniform(-hue, hue) * 255\n#     hsv_image = hsv_image.point(lambda x: (x + hue_shift) % 256)\n#     jittered_image = hsv_image.convert(\"RGB\")\n    \n#     jittered_image = cv2.cvtColor(np.array(jittered_image), cv2.COLOR_RGB2BGR)\n\n#     return jittered_image\n\n\n# def gaussian_blur(image, sigma=1):\n    \n#     return cv2.GaussianBlur(image, (3, 3), 0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images=[]\nimage=cv2.imread(\"/kaggle/input/indian-sign-language/Test/0/0_1.jpg\")\n# images.append(skimage.util.random_noise(image))\n# images.append(gaussian_blur(image))\n# images.append(color_jittering(image))\n# images.append(elastic_transform(image))\nfig, axes = plt.subplots(2, 2)\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(images[i])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    print(images[2].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Example usage\nimage = Image.open(\"image.jpg\")  # Replace \"image.jpg\" with the actual image path\nnoisy_image = add_gaussian_noise(image, mean=0, std=10)\njittered_image = color_jittering(image, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\ntransformed_image = elastic_transform(image, alpha=200, sigma=10)\nblurred_image = gaussian_blur(image, sigma=1)\nrotated_image = rotate_image(image, angle=30)\nadjusted_image = adjust_brightness_contrast(image, brightness=0.2, contrast=0.2)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}